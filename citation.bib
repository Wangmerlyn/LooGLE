@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{dong2023survey,
      title={A Survey on Long Text Modeling with Transformers}, 
      author={Zican Dong and Tianyi Tang and Lunyi Li and Wayne Xin Zhao},
      year={2023},
      eprint={2302.14502},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{tay2020long,
      title={Long Range Arena: A Benchmark for Efficient Transformers}, 
      author={Yi Tay and Mostafa Dehghani and Samira Abnar and Yikang Shen and Dara Bahri and Philip Pham and Jinfeng Rao and Liu Yang and Sebastian Ruder and Donald Metzler},
      year={2020},
      eprint={2011.04006},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{tay2022efficient,
      title={Efficient Transformers: A Survey}, 
      author={Yi Tay and Mostafa Dehghani and Dara Bahri and Donald Metzler},
      year={2022},
      eprint={2009.06732},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{bulatov2022recurrent,
      title={Recurrent Memory Transformer}, 
      author={Aydar Bulatov and Yuri Kuratov and Mikhail S. Burtsev},
      year={2022},
      eprint={2207.06881},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{wu2021recursively,
      title={Recursively Summarizing Books with Human Feedback}, 
      author={Jeff Wu and Long Ouyang and Daniel M. Ziegler and Nisan Stiennon and Ryan Lowe and Jan Leike and Paul Christiano},
      year={2021},
      eprint={2109.10862},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{gidiotis2020divideandconquer,
      title={A Divide-and-Conquer Approach to the Summarization of Long Documents}, 
      author={Alexios Gidiotis and Grigorios Tsoumakas},
      year={2020},
      eprint={2004.06190},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{zhou2022finegrained,
      title={Fine-Grained Distillation for Long Document Retrieval}, 
      author={Yucheng Zhou and Tao Shen and Xiubo Geng and Chongyang Tao and Guodong Long and Can Xu and Daxin Jiang},
      year={2022},
      eprint={2212.10423},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
@misc{cohan2018discourseaware,
      title={A Discourse-Aware Attention Model for Abstractive Summarization of Long Documents}, 
      author={Arman Cohan and Franck Dernoncourt and Doo Soon Kim and Trung Bui and Seokhwan Kim and Walter Chang and Nazli Goharian},
      year={2018},
      eprint={1804.05685},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{sharma2019bigpatent,
      title={BIGPATENT: A Large-Scale Dataset for Abstractive and Coherent Summarization}, 
      author={Eva Sharma and Chen Li and Lu Wang},
      year={2019},
      eprint={1906.03741},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{huang2021efficient,
      title={Efficient Attentions for Long Document Summarization}, 
      author={Luyang Huang and Shuyang Cao and Nikolaus Parulian and Heng Ji and Lu Wang},
      year={2021},
      eprint={2104.02112},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{narrativeqa,
author = {Tom\'a\v s Ko\v cisk\'y and Jonathan Schwarz and Phil Blunsom and
          Chris Dyer and Karl Moritz Hermann and G\'abor Melis and
          Edward Grefenstette},
title = {The {NarrativeQA} Reading Comprehension Challenge},
journal = {Transactions of the Association for Computational Linguistics},
url = {https://TBD},
volume = {TBD},
year = {2018},
pages = {TBD},
}
@misc{yang2018hotpotqa,
      title={HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering}, 
      author={Zhilin Yang and Peng Qi and Saizheng Zhang and Yoshua Bengio and William W. Cohen and Ruslan Salakhutdinov and Christopher D. Manning},
      year={2018},
      eprint={1809.09600},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{manakul2021longspan,
      title={Long-Span Summarization via Local Attention and Content Selection}, 
      author={Potsawee Manakul and Mark J. F. Gales},
      year={2021},
      eprint={2105.03801},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{subramanian2020extractive,
      title={On Extractive and Abstractive Neural Document Summarization with Transformer Language Models}, 
      author={Sandeep Subramanian and Raymond Li and Jonathan Pilault and Christopher Pal},
      year={2020},
      eprint={1909.03186},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{zhang2022hegel,
      title={HEGEL: Hypergraph Transformer for Long Document Summarization}, 
      author={Haopeng Zhang and Xiao Liu and Jiawei Zhang},
      year={2022},
      eprint={2210.04126},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{xiao2019extractive,
      title={Extractive Summarization of Long Documents by Combining Global and Local Context}, 
      author={Wen Xiao and Giuseppe Carenini},
      year={2019},
      eprint={1909.08089},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{kitaev2020reformer,
      title={Reformer: The Efficient Transformer}, 
      author={Nikita Kitaev and Łukasz Kaiser and Anselm Levskaya},
      year={2020},
      eprint={2001.04451},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{wang2020linformer,
      title={Linformer: Self-Attention with Linear Complexity}, 
      author={Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
      year={2020},
      eprint={2006.04768},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{katharopoulos2020transformers,
      title={Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention}, 
      author={Angelos Katharopoulos and Apoorv Vyas and Nikolaos Pappas and François Fleuret},
      year={2020},
      eprint={2006.16236},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{guo2022longt5,
      title={LongT5: Efficient Text-To-Text Transformer for Long Sequences}, 
      author={Mandy Guo and Joshua Ainslie and David Uthus and Santiago Ontanon and Jianmo Ni and Yun-Hsuan Sung and Yinfei Yang},
      year={2022},
      eprint={2112.07916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{beltagy2020longformer,
      title={Longformer: The Long-Document Transformer}, 
      author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
      year={2020},
      eprint={2004.05150},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{zaheer2021big,
      title={Big Bird: Transformers for Longer Sequences}, 
      author={Manzil Zaheer and Guru Guruganesh and Avinava Dubey and Joshua Ainslie and Chris Alberti and Santiago Ontanon and Philip Pham and Anirudh Ravula and Qifan Wang and Li Yang and Amr Ahmed},
      year={2021},
      eprint={2007.14062},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{bulatov2023scaling,
      title={Scaling Transformer to 1M tokens and beyond with RMT}, 
      author={Aydar Bulatov and Yuri Kuratov and Mikhail S. Burtsev},
      year={2023},
      eprint={2304.11062},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{sun2023pearl,
      title={PEARL: Prompting Large Language Models to Plan and Execute Actions Over Long Documents}, 
      author={Simeng Sun and Yang Liu and Shuohang Wang and Chenguang Zhu and Mohit Iyyer},
      year={2023},
      eprint={2305.14564},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{pereira2022visconde,
      title={Visconde: Multi-document QA with GPT-3 and Neural Reranking}, 
      author={Jayr Pereira and Robson Fidalgo and Roberto Lotufo and Rodrigo Nogueira},
      year={2022},
      eprint={2212.09656},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{liu2022psp,
      title={PSP: Pre-trained Soft Prompts for Few-Shot Abstractive Summarization}, 
      author={Xiaochen Liu and Yang Gao and Yu Bai and Jiawei Li and Yinan Hu and Heyan Huang and Boxing Chen},
      year={2022},
      eprint={2204.04413},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{raposo2022documentlevel,
      title={Document-Level Abstractive Summarization}, 
      author={Gonçalo Raposo and Afonso Raposo and Ana Sofia Carmo},
      year={2022},
      eprint={2212.03013},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{Koh_2022,
	doi = {10.1145/3545176},
	url = {https://doi.org/10.1145\%2F3545176},
	year = 2022,
	month = {dec},
	publisher = {Association for Computing Machinery ({ACM})},
	volume = {55},
	number = {8},
	pages = {1--35},
	author = {Huan Yee Koh and Jiaxin Ju and Ming Liu and Shirui Pan},
	title = {An Empirical Survey on Long Document Summarization: Datasets, Models, and Metrics},
	journal = {{ACM} Computing Surveys}
}
@misc{dasigi2021dataset,
      title={A Dataset of Information-Seeking Questions and Answers Anchored in Research Papers}, 
      author={Pradeep Dasigi and Kyle Lo and Iz Beltagy and Arman Cohan and Noah A. Smith and Matt Gardner},
      year={2021},
      eprint={2105.03011},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{hudson2022muld,
      title={MuLD: The Multitask Long Document Benchmark}, 
      author={G Thomas Hudson and Noura Al Moubayed},
      year={2022},
      eprint={2202.07362},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{liu2023geval,
      title={G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment}, 
      author={Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu},
      year={2023},
      eprint={2303.16634},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@inproceedings{Rajpurkar2016SQuAD10,
title={SQuAD: 100, 000+ Questions for Machine Comprehension of Text},
author={Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
booktitle={EMNLP},
year={2016}
}
@misc{maudslay2022homonymy,
      title={Homonymy Information for English WordNet}, 
      author={Rowan Hall Maudslay and Simone Teufel},
      year={2022},
      eprint={2212.08388},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ding2023longnet,
      title={LongNet: Scaling Transformers to 1,000,000,000 Tokens}, 
      author={Jiayu Ding and Shuming Ma and Li Dong and Xingxing Zhang and Shaohan Huang and Wenhui Wang and Nanning Zheng and Furu Wei},
      year={2023},
      eprint={2307.02486},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{dao2022flashattention,
      title={FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness}, 
      author={Tri Dao and Daniel Y. Fu and Stefano Ermon and Atri Rudra and Christopher Ré},
      year={2022},
      eprint={2205.14135},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{chi2023dissecting,
      title={Dissecting Transformer Length Extrapolation via the Lens of Receptive Field Analysis}, 
      author={Ta-Chung Chi and Ting-Han Fan and Alexander I. Rudnicky and Peter J. Ramadge},
      year={2023},
      eprint={2212.10356},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{shaham2022scrolls,
      title={SCROLLS: Standardized CompaRison Over Long Language Sequences}, 
      author={Uri Shaham and Elad Segal and Maor Ivgi and Avia Efrat and Ori Yoran and Adi Haviv and Ankit Gupta and Wenhan Xiong and Mor Geva and Jonathan Berant and Omer Levy},
      year={2022},
      eprint={2201.03533},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{kryściński2022booksum,
      title={BookSum: A Collection of Datasets for Long-form Narrative Summarization}, 
      author={Wojciech Kryściński and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},
      year={2022},
      eprint={2105.08209},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{trivedi2022musique,
      title={MuSiQue: Multihop Questions via Single-hop Question Composition}, 
      author={Harsh Trivedi and Niranjan Balasubramanian and Tushar Khot and Ashish Sabharwal},
      year={2022},
      eprint={2108.00573},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{wang2022squality,
      title={SQuALITY: Building a Long-Document Summarization Dataset the Hard Way}, 
      author={Alex Wang and Richard Yuanzhe Pang and Angelica Chen and Jason Phang and Samuel R. Bowman},
      year={2022},
      eprint={2205.11465},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{angelidis2020extractive,
      title={Extractive Opinion Summarization in Quantized Transformer Spaces}, 
      author={Stefanos Angelidis and Reinald Kim Amplayo and Yoshihiko Suhara and Xiaolan Wang and Mirella Lapata},
      year={2020},
      eprint={2012.04443},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ram2023incontext,
      title={In-Context Retrieval-Augmented Language Models}, 
      author={Ori Ram and Yoav Levine and Itay Dalmedigos and Dor Muhlgay and Amnon Shashua and Kevin Leyton-Brown and Yoav Shoham},
      year={2023},
      eprint={2302.00083},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{izacard2022atlas,
      title={Atlas: Few-shot Learning with Retrieval Augmented Language Models}, 
      author={Gautier Izacard and Patrick Lewis and Maria Lomeli and Lucas Hosseini and Fabio Petroni and Timo Schick and Jane Dwivedi-Yu and Armand Joulin and Sebastian Riedel and Edouard Grave},
      year={2022},
      eprint={2208.03299},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{shaham2023zeroscrolls,
      title={ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding}, 
      author={Uri Shaham and Maor Ivgi and Avia Efrat and Jonathan Berant and Omer Levy},
      year={2023},
      eprint={2305.14196},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{an2023leval,
      title={L-Eval: Instituting Standardized Evaluation for Long Context Language Models}, 
      author={Chenxin An and Shansan Gong and Ming Zhong and Mukai Li and Jun Zhang and Lingpeng Kong and Xipeng Qiu},
      year={2023},
      eprint={2307.11088},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{bai2023longbench,
      title={LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding}, 
      author={Yushi Bai and Xin Lv and Jiajie Zhang and Hongchang Lyu and Jiankai Tang and Zhidian Huang and Zhengxiao Du and Xiao Liu and Aohan Zeng and Lei Hou and Yuxiao Dong and Jie Tang and Juanzi Li},
      year={2023},
      eprint={2308.14508},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{li2023unlocking,
      title={Unlocking Context Constraints of LLMs: Enhancing Context Efficiency of LLMs with Self-Information-Based Content Filtering}, 
      author={Yucheng Li},
      year={2023},
      eprint={2304.12102},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{kim2023interannotator,
      title={Inter-Annotator Agreement in the Wild: Uncovering Its Emerging Roles and Considerations in Real-World Scenarios}, 
      author={NamHyeok Kim and Chanjun Park},
      year={2023},
      eprint={2306.14373},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}


@misc{mao2023drl4route,
      title={DRL4Route: A Deep Reinforcement Learning Framework for Pick-up and Delivery Route Prediction}, 
      author={Xiaowei Mao and Haomin Wen and Hengrui Zhang and Huaiyu Wan and Lixia Wu and Jianbin Zheng and Haoyuan Hu and Youfang Lin},
      year={2023},
      eprint={2307.16246},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{li2023large,
      title={Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts}, 
      author={Zihao Li and Samuel Belkadi and Nicolo Micheletti and Lifeng Han and Matthew Shardlow and Goran Nenadic},
      year={2023},
      eprint={2309.13202},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{mukherjee2023employing,
      title={Employing Deep Learning and Structured Information Retrieval to Answer Clarification Questions on Bug Reports}, 
      author={Usmi Mukherjee and Mohammad Masudur Rahman},
      year={2023},
      eprint={2304.12494},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}
@misc{sharma2023augmenting,
      title={Augmenting text for spoken language understanding with Large Language Models}, 
      author={Roshan Sharma and Suyoun Kim and Daniel Lazar and Trang Le and Akshat Shrivastava and Kwanghoon Ahn and Piyush Kansal and Leda Sari and Ozlem Kalinli and Michael Seltzer},
      year={2023},
      eprint={2309.09390},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{engelbach2023finetuning,
      title={Fine-tuning and aligning question answering models for complex information extraction tasks}, 
      author={Matthias Engelbach and Dennis Klau and Felix Scheerer and Jens Drawehn and Maximilien Kintz},
      year={2023},
      eprint={2309.14805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{suri2023large,
      title={Do Large Language Models Show Decision Heuristics Similar to Humans? A Case Study Using GPT-3.5}, 
      author={Gaurav Suri and Lily R. Slater and Ali Ziaee and Morgan Nguyen},
      year={2023},
      eprint={2305.04400},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}
@misc{liu2023calibrating,
      title={Calibrating LLM-Based Evaluator}, 
      author={Yuxuan Liu and Tianchi Yang and Shaohan Huang and Zihan Zhang and Haizhen Huang and Furu Wei and Weiwei Deng and Feng Sun and Qi Zhang},
      year={2023},
      eprint={2309.13308},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{touvron2023llama,
      title={LLaMA: Open and Efficient Foundation Language Models}, 
      author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
      year={2023},
      eprint={2302.13971},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{peng2023rwkv,
      title={RWKV: Reinventing RNNs for the Transformer Era}, 
      author={Bo Peng and Eric Alcaide and Quentin Anthony and Alon Albalak and Samuel Arcadinho and Huanqi Cao and Xin Cheng and Michael Chung and Matteo Grella and Kranthi Kiran GV and Xuzheng He and Haowen Hou and Przemyslaw Kazienko and Jan Kocon and Jiaming Kong and Bartlomiej Koptyra and Hayden Lau and Krishna Sri Ipsit Mantri and Ferdinand Mom and Atsushi Saito and Xiangru Tang and Bolun Wang and Johan S. Wind and Stansilaw Wozniak and Ruichong Zhang and Zhenyuan Zhang and Qihang Zhao and Peng Zhou and Jian Zhu and Rui-Jie Zhu},
      year={2023},
      eprint={2305.13048},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tworkowski2023focused,
      title={Focused Transformer: Contrastive Training for Context Scaling}, 
      author={Szymon Tworkowski and Konrad Staniszewski and Mikołaj Pacek and Yuhuai Wu and Henryk Michalewski and Piotr Miłoś},
      year={2023},
      eprint={2307.03170},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{du2022glm,
  title={GLM: General Language Model Pretraining with Autoregressive Blank Infilling},
  author={Du, Zhengxiao and Qian, Yujie and Liu, Xiao and Ding, Ming and Qiu, Jiezhong and Yang, Zhilin and Tang, Jie},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={320--335},
  year={2022}
}


@misc{liu2023lost,
      title={Lost in the Middle: How Language Models Use Long Contexts}, 
      author={Nelson F. Liu and Kevin Lin and John Hewitt and Ashwin Paranjape and Michele Bevilacqua and Fabio Petroni and Percy Liang},
      year={2023},
      eprint={2307.03172},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{lee2023rlaif,
      title={RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback}, 
      author={Harrison Lee and Samrat Phatale and Hassan Mansoor and Kellie Lu and Thomas Mesnard and Colton Bishop and Victor Carbune and Abhinav Rastogi},
      year={2023},
      eprint={2309.00267},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{meister2021sparse,
      title={Is Sparse Attention more Interpretable?}, 
      author={Clara Meister and Stefan Lazov and Isabelle Augenstein and Ryan Cotterell},
      year={2021},
      eprint={2106.01087},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{bessonov2023recurrent,
      title={Recurrent Memory Decision Transformer}, 
      author={Arkadii Bessonov and Alexey Staroverov and Huzhenyu Zhang and Alexey K. Kovalev and Dmitry Yudin and Aleksandr I. Panov},
      year={2023},
      eprint={2306.09459},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{zeng2023matters,
      title={What Matters in Training a GPT4-Style Language Model with Multimodal Inputs?}, 
      author={Yan Zeng and Hanbo Zhang and Jiani Zheng and Jiangnan Xia and Guoqiang Wei and Yang Wei and Yuchen Zhang and Tao Kong},
      year={2023},
      eprint={2307.02469},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{chen2023robust,
      title={How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks}, 
      author={Xuanting Chen and Junjie Ye and Can Zu and Nuo Xu and Rui Zheng and Minlong Peng and Jie Zhou and Tao Gui and Qi Zhang and Xuanjing Huang},
      year={2023},
      eprint={2303.00293},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{ye2023comprehensive,
      title={A Comprehensive Capability Analysis of GPT-3 and GPT-3.5 Series Models}, 
      author={Junjie Ye and Xuanting Chen and Nuo Xu and Can Zu and Zekai Shao and Shichun Liu and Yuhan Cui and Zeyang Zhou and Chao Gong and Yang Shen and Jie Zhou and Siming Chen and Tao Gui and Qi Zhang and Xuanjing Huang},
      year={2023},
      eprint={2303.10420},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{chen2023extending,
      title={Extending Context Window of Large Language Models via Positional Interpolation}, 
      author={Shouyuan Chen and Sherman Wong and Liangjian Chen and Yuandong Tian},
      year={2023},
      eprint={2306.15595},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{xu2023retrieval,
      title={Retrieval meets Long Context Large Language Models}, 
      author={Peng Xu and Wei Ping and Xianchao Wu and Lawrence McAfee and Chen Zhu and Zihan Liu and Sandeep Subramanian and Evelina Bakhturina and Mohammad Shoeybi and Bryan Catanzaro},
      year={2023},
      eprint={2310.03025},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{askari2023retrieval,
      title={Retrieval for Extremely Long Queries and Documents with RPRS: a Highly Efficient and Effective Transformer-based Re-Ranker}, 
      author={Arian Askari and Suzan Verberne and Amin Abolghasemi and Wessel Kraaij and Gabriella Pasi},
      year={2023},
      eprint={2303.01200},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
@misc{kojima2023large,
      title={Large Language Models are Zero-Shot Reasoners}, 
      author={Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa},
      year={2023},
      eprint={2205.11916},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{wei2023chainofthought,
      title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models}, 
      author={Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc Le and Denny Zhou},
      year={2023},
      eprint={2201.11903},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{chen2023longlora,
      title={LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models}, 
      author={Yukang Chen and Shengju Qian and Haotian Tang and Xin Lai and Zhijian Liu and Song Han and Jiaya Jia},
      year={2023},
      eprint={2309.12307},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{anil2021largescale,
      title={Large-Scale Differentially Private BERT}, 
      author={Rohan Anil and Badih Ghazi and Vineet Gupta and Ravi Kumar and Pasin Manurangsi},
      year={2021},
      eprint={2108.01624},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{roy2021recent,
      title={Recent Trends in Named Entity Recognition (NER)}, 
      author={Arya Roy},
      year={2021},
      eprint={2101.11420},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{xiong2023effective,
      title={Effective Long-Context Scaling of Foundation Models}, 
      author={Wenhan Xiong and Jingyu Liu and Igor Molybog and Hejia Zhang and Prajjwal Bhargava and Rui Hou and Louis Martin and Rashi Rungta and Karthik Abinav Sankararaman and Barlas Oguz and Madian Khabsa and Han Fang and Yashar Mehdad and Sharan Narang and Kshitiz Malik and Angela Fan and Shruti Bhosale and Sergey Edunov and Mike Lewis and Sinong Wang and Hao Ma},
      year={2023},
      eprint={2309.16039},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@misc{li2023functional,
      title={Functional Interpolation for Relative Positions Improves Long Context Transformers}, 
      author={Shanda Li and Chong You and Guru Guruganesh and Joshua Ainslie and Santiago Ontanon and Manzil Zaheer and Sumit Sanghai and Yiming Yang and Sanjiv Kumar and Srinadh Bhojanapalli},
      year={2023},
      eprint={2310.04418},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{devlin2019bert,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ouyang2022training,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{song2020mpnet,
      title={MPNet: Masked and Permuted Pre-training for Language Understanding}, 
      author={Kaitao Song and Xu Tan and Tao Qin and Jianfeng Lu and Tie-Yan Liu},
      year={2020},
      eprint={2004.09297},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

